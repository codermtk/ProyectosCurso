{
  "nodes": [
    {
      "id": "customFunction_0",
      "position": {
        "x": 685,
        "y": 222.29209222523332
      },
      "type": "customNode",
      "data": {
        "id": "customFunction_0",
        "label": "Custom JS Function",
        "version": 3,
        "name": "customFunction",
        "type": "CustomFunction",
        "baseClasses": [
          "CustomFunction",
          "Utilities"
        ],
        "tags": [
          "Utilities"
        ],
        "category": "Utilities",
        "description": "Execute custom javascript function",
        "inputParams": [
          {
            "label": "Input Variables",
            "name": "functionInputVariables",
            "description": "Input variables can be used in the function with prefix $. For example: $var",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "customFunction_0-input-functionInputVariables-json"
          },
          {
            "label": "Function Name",
            "name": "functionName",
            "type": "string",
            "optional": true,
            "placeholder": "My Function",
            "id": "customFunction_0-input-functionName-string"
          },
          {
            "label": "Javascript Function",
            "name": "javascriptFunction",
            "type": "code",
            "id": "customFunction_0-input-javascriptFunction-code"
          }
        ],
        "inputAnchors": [
          {
            "label": "Additional Tools",
            "description": "Tools can be used in the function with $tools.{tool_name}.invoke(args)",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "customFunction_0-input-tools-Tool"
          }
        ],
        "inputs": {
          "functionInputVariables": "",
          "functionName": "extractor_de_links",
          "tools": [
            "{{braveSearchAPI_0.data.instance}}"
          ],
          "javascriptFunction": "async function searchBrave(query) {\n    try {\n        if (!$tools) {\n            throw new Error(\"No se han proporcionado herramientas ($tools es undefined). Verifica que el nodo Brave Search esté conectado correctamente.\");\n        }\n\n        const braveTool = $tools['brave-search'];\n        if (!braveTool || typeof braveTool.invoke !== 'function') {\n            throw new Error(\"Herramienta Brave Search no disponible o no conectada correctamente en el flujo\");\n        }\n\n        if (!query || typeof query !== 'string') {\n            throw new Error(\"Query inválido o vacío\");\n        }\n\n        console.log(\"Búsqueda realizada:\", query);\n\n        const searchConfig = {\n            input: query\n        };\n\n        const result = await braveTool.invoke(searchConfig);\n        \n        if (typeof result === 'string') {\n            console.log(\"Resultado obtenido:\", result);\n            return result;\n        }\n        \n        const finalResult = result.toolOutput || JSON.stringify(result, null, 2);\n        console.log(\"Resultado obtenido:\", finalResult);\n        return finalResult;\n\n    } catch (error) {\n        console.error(\"Error detallado:\", error.message);\n        return `Error en la búsqueda: ${error.message}`;\n    }\n}\n\nif (typeof $tools === 'undefined') {\n    console.error(\"Error: $tools no está definido\");\n    return \"Error: Herramientas no disponibles. Verifica la conexión con el nodo Brave Search.\";\n}\n\nconst query = $flow.input;\nif (!query) {\n    return \"Error: No se proporcionó un término de búsqueda\";\n}\n\nreturn await searchBrave(query);"
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "customFunction_0-output-output-string|number|boolean|json|array",
                "name": "output",
                "label": "Output",
                "description": "",
                "type": "string | number | boolean | json | array"
              },
              {
                "id": "customFunction_0-output-EndingNode-CustomFunction",
                "name": "EndingNode",
                "label": "Ending Node",
                "description": "",
                "type": "CustomFunction"
              }
            ],
            "default": "output"
          }
        ],
        "outputs": {
          "output": "output"
        },
        "selected": false
      },
      "width": 300,
      "height": 726,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 685,
        "y": 222.29209222523332
      }
    },
    {
      "id": "braveSearchAPI_0",
      "position": {
        "x": 317.1524434587012,
        "y": 36.501844307742886
      },
      "type": "customNode",
      "data": {
        "id": "braveSearchAPI_0",
        "label": "BraveSearch API",
        "version": 1,
        "name": "braveSearchAPI",
        "type": "BraveSearchAPI",
        "baseClasses": [
          "BraveSearchAPI",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Wrapper around BraveSearch API - a real-time API to access Brave search results",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "braveSearchApi"
            ],
            "id": "braveSearchAPI_0-input-credential-credential"
          }
        ],
        "inputAnchors": [],
        "inputs": {},
        "outputAnchors": [
          {
            "id": "braveSearchAPI_0-output-braveSearchAPI-BraveSearchAPI|Tool|StructuredTool|Runnable",
            "name": "braveSearchAPI",
            "label": "BraveSearchAPI",
            "description": "Wrapper around BraveSearch API - a real-time API to access Brave search results",
            "type": "BraveSearchAPI | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 276,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 317.1524434587012,
        "y": 36.501844307742886
      }
    },
    {
      "id": "llmChain_0",
      "position": {
        "x": 1507.370724100358,
        "y": 457.15396058836126
      },
      "type": "customNode",
      "data": {
        "id": "llmChain_0",
        "label": "LLM Chain",
        "version": 3,
        "name": "llmChain",
        "type": "LLMChain",
        "baseClasses": [
          "LLMChain",
          "BaseChain",
          "Runnable"
        ],
        "category": "Chains",
        "description": "Chain to run queries against LLMs",
        "inputParams": [
          {
            "label": "Chain Name",
            "name": "chainName",
            "type": "string",
            "placeholder": "Name Your Chain",
            "optional": true,
            "id": "llmChain_0-input-chainName-string"
          }
        ],
        "inputAnchors": [
          {
            "label": "Language Model",
            "name": "model",
            "type": "BaseLanguageModel",
            "id": "llmChain_0-input-model-BaseLanguageModel"
          },
          {
            "label": "Prompt",
            "name": "prompt",
            "type": "BasePromptTemplate",
            "id": "llmChain_0-input-prompt-BasePromptTemplate"
          },
          {
            "label": "Output Parser",
            "name": "outputParser",
            "type": "BaseLLMOutputParser",
            "optional": true,
            "id": "llmChain_0-input-outputParser-BaseLLMOutputParser"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "llmChain_0-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "model": "{{chatGoogleGenerativeAI_0.data.instance}}",
          "prompt": "{{promptTemplate_0.data.instance}}",
          "outputParser": "",
          "inputModeration": "",
          "chainName": "procesador_de_links"
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "llmChain_0-output-llmChain-LLMChain|BaseChain|Runnable",
                "name": "llmChain",
                "label": "LLM Chain",
                "description": "",
                "type": "LLMChain | BaseChain | Runnable"
              },
              {
                "id": "llmChain_0-output-outputPrediction-string|json",
                "name": "outputPrediction",
                "label": "Output Prediction",
                "description": "",
                "type": "string | json"
              }
            ],
            "default": "llmChain"
          }
        ],
        "outputs": {
          "output": "outputPrediction"
        },
        "selected": false
      },
      "width": 300,
      "height": 508,
      "selected": false,
      "positionAbsolute": {
        "x": 1507.370724100358,
        "y": 457.15396058836126
      },
      "dragging": false
    },
    {
      "id": "promptTemplate_0",
      "position": {
        "x": 1115.5516544289067,
        "y": 476.34551431235116
      },
      "type": "customNode",
      "data": {
        "id": "promptTemplate_0",
        "label": "Prompt Template",
        "version": 1,
        "name": "promptTemplate",
        "type": "PromptTemplate",
        "baseClasses": [
          "PromptTemplate",
          "BaseStringPromptTemplate",
          "BasePromptTemplate",
          "Runnable"
        ],
        "category": "Prompts",
        "description": "Schema to represent a basic prompt for an LLM",
        "inputParams": [
          {
            "label": "Template",
            "name": "template",
            "type": "string",
            "rows": 4,
            "placeholder": "What is a good name for a company that makes {product}?",
            "id": "promptTemplate_0-input-template-string"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "promptTemplate_0-input-promptValues-json"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "template": "Tu trabajo es recolectar links. Te voy a pasar un chunk de texto que contiene información y links, y tu trabajo es devolver en formato JSON cada uno de los links que aparezcan dentro siguiendo la siguiente estructura: \"link1\":\"\", \"link2\":\"\",\"link3\":\"\" etc\n\nInformación a procesar:\n{info}",
          "promptValues": "{\"info\":\"{{customFunction_0.data.instance}}\"}"
        },
        "outputAnchors": [
          {
            "id": "promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable",
            "name": "promptTemplate",
            "label": "PromptTemplate",
            "description": "Schema to represent a basic prompt for an LLM",
            "type": "PromptTemplate | BaseStringPromptTemplate | BasePromptTemplate | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 513,
      "selected": false,
      "positionAbsolute": {
        "x": 1115.5516544289067,
        "y": 476.34551431235116
      },
      "dragging": false
    },
    {
      "id": "chatGoogleGenerativeAI_0",
      "position": {
        "x": 1112.870358603893,
        "y": -224.01273565339113
      },
      "type": "customNode",
      "data": {
        "id": "chatGoogleGenerativeAI_0",
        "label": "ChatGoogleGenerativeAI",
        "version": 3,
        "name": "chatGoogleGenerativeAI",
        "type": "ChatGoogleGenerativeAI",
        "baseClasses": [
          "ChatGoogleGenerativeAI",
          "LangchainChatGoogleGenerativeAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "googleGenerativeAI"
            ],
            "optional": false,
            "description": "Google Generative AI credential.",
            "id": "chatGoogleGenerativeAI_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gemini-1.5-flash-latest",
            "id": "chatGoogleGenerativeAI_0-input-modelName-asyncOptions"
          },
          {
            "label": "Custom Model Name",
            "name": "customModelName",
            "type": "string",
            "placeholder": "gemini-1.5-pro-exp-0801",
            "description": "Custom model name to use. If provided, it will override the model selected",
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-customModelName-string"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-temperature-number"
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-streaming-boolean"
          },
          {
            "label": "Max Output Tokens",
            "name": "maxOutputTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-maxOutputTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-topP-number"
          },
          {
            "label": "Top Next Highest Probability Tokens",
            "name": "topK",
            "type": "number",
            "description": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-topK-number"
          },
          {
            "label": "Harm Category",
            "name": "harmCategory",
            "type": "multiOptions",
            "description": "Refer to <a target=\"_blank\" href=\"https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/configure-safety-attributes#safety_attribute_definitions\">official guide</a> on how to use Harm Category",
            "options": [
              {
                "label": "Dangerous",
                "name": "HARM_CATEGORY_DANGEROUS_CONTENT"
              },
              {
                "label": "Harassment",
                "name": "HARM_CATEGORY_HARASSMENT"
              },
              {
                "label": "Hate Speech",
                "name": "HARM_CATEGORY_HATE_SPEECH"
              },
              {
                "label": "Sexually Explicit",
                "name": "HARM_CATEGORY_SEXUALLY_EXPLICIT"
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-harmCategory-multiOptions"
          },
          {
            "label": "Harm Block Threshold",
            "name": "harmBlockThreshold",
            "type": "multiOptions",
            "description": "Refer to <a target=\"_blank\" href=\"https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/configure-safety-attributes#safety_setting_thresholds\">official guide</a> on how to use Harm Block Threshold",
            "options": [
              {
                "label": "Low and Above",
                "name": "BLOCK_LOW_AND_ABOVE"
              },
              {
                "label": "Medium and Above",
                "name": "BLOCK_MEDIUM_AND_ABOVE"
              },
              {
                "label": "None",
                "name": "BLOCK_NONE"
              },
              {
                "label": "Only High",
                "name": "BLOCK_ONLY_HIGH"
              },
              {
                "label": "Threshold Unspecified",
                "name": "HARM_BLOCK_THRESHOLD_UNSPECIFIED"
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-harmBlockThreshold-multiOptions"
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
            "default": false,
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-allowImageUploads-boolean"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gemini-2.0-flash-001",
          "customModelName": "",
          "temperature": "0.1",
          "streaming": true,
          "maxOutputTokens": "",
          "topP": "",
          "topK": "",
          "harmCategory": "",
          "harmBlockThreshold": "",
          "allowImageUploads": ""
        },
        "outputAnchors": [
          {
            "id": "chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatGoogleGenerativeAI",
            "label": "ChatGoogleGenerativeAI",
            "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
            "type": "ChatGoogleGenerativeAI | LangchainChatGoogleGenerativeAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 670,
      "selected": false,
      "positionAbsolute": {
        "x": 1112.870358603893,
        "y": -224.01273565339113
      },
      "dragging": false
    },
    {
      "id": "customFunction_1",
      "position": {
        "x": 1916.477105496279,
        "y": 223.6826688678588
      },
      "type": "customNode",
      "data": {
        "id": "customFunction_1",
        "label": "Custom JS Function",
        "version": 3,
        "name": "customFunction",
        "type": "CustomFunction",
        "baseClasses": [
          "CustomFunction",
          "Utilities"
        ],
        "tags": [
          "Utilities"
        ],
        "category": "Utilities",
        "description": "Execute custom javascript function",
        "inputParams": [
          {
            "label": "Input Variables",
            "name": "functionInputVariables",
            "description": "Input variables can be used in the function with prefix $. For example: $var",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "customFunction_1-input-functionInputVariables-json"
          },
          {
            "label": "Function Name",
            "name": "functionName",
            "type": "string",
            "optional": true,
            "placeholder": "My Function",
            "id": "customFunction_1-input-functionName-string"
          },
          {
            "label": "Javascript Function",
            "name": "javascriptFunction",
            "type": "code",
            "id": "customFunction_1-input-javascriptFunction-code"
          }
        ],
        "inputAnchors": [
          {
            "label": "Additional Tools",
            "description": "Tools can be used in the function with $tools.{tool_name}.invoke(args)",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "customFunction_1-input-tools-Tool"
          }
        ],
        "inputs": {
          "functionInputVariables": "{\"link\":\"{{llmChain_0.data.instance}}\"}",
          "functionName": "link_scraper",
          "tools": "",
          "javascriptFunction": "const fetch = require('node-fetch');\nconst cheerio = require('cheerio');\n\nasync function getCleanedText(url) {\n    try {\n        console.log(`Iniciando proceso para URL: ${url}`);\n        \n        const controller = new AbortController();\n        const timeout = setTimeout(() => {\n            controller.abort();\n        }, 10000); \n\n        console.log('Intentando fetch...');\n        const response = await fetch(url, {\n            signal: controller.signal,\n            headers: {\n                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n                'Accept-Language': 'en-US,en;q=0.5'\n            }\n        });\n        \n        clearTimeout(timeout);\n\n        if (!response.ok) { \n            throw new Error(`HTTP error! Status: ${response.status}`);\n        }\n\n        console.log('Fetch exitoso, obteniendo texto...');\n        const html = await response.text();\n        \n        console.log('Cargando contenido en cheerio...');\n        const $ = cheerio.load(html);\n        \n        console.log('Limpiando elementos no deseados...');\n        $('script, style, noscript, svg, img, iframe, link').remove();\n        \n        console.log('Extrayendo texto...');\n        const textContent = $('body')\n            .find('h1, h2, h3, h4, h5, h6, p, li, td, th, article, section')\n            .map((i, el) => {\n                const text = $(el).text().trim().replace(/\\s+/g, ' ');\n                // Log del texto encontrado (primeros 100 caracteres)\n                if (text.length > 0) {\n                    console.log(`Encontrado texto: ${text.substring(0, 100)}...`);\n                }\n                return text;\n            })\n            .get()\n            .join('\\n\\n')\n            .replace(/(\\n\\s*){3,}/g, '\\n\\n') \n            .trim();\n\n        if (!textContent) {\n            console.log('No se encontró texto en la página');\n            return 'No se encontró contenido legible en la página';\n        }\n\n        console.log(`Procesamiento exitoso para ${url}`);\n        return textContent;\n\n    } catch (error) {\n        if (error.name === 'AbortError') {\n            console.error(`Timeout alcanzado para ${url}`);\n            return `Error: La página tardó demasiado en responder`;\n        }\n        console.error(`Error detallado procesando ${url}:`, error);\n        return `Error: ${error.message}`;\n    }\n}\n\nasync function processFirstFiveLinks(jsonString) {\n    try {\n        console.log('Iniciando procesamiento de links...');\n        \n        const cleanJsonString = jsonString\n            .replace(/^```json\\n/, '')\n            .replace(/\\n```$/, '')\n            .trim();\n\n        console.log('JSON limpio:', cleanJsonString.substring(0, 100) + '...');\n        \n        const links = JSON.parse(cleanJsonString);\n        \n        const firstFiveEntries = Object.entries(links)\n            .filter(([key]) => key.startsWith('link'))\n            .slice(0, 5);\n\n        console.log(`Procesando ${firstFiveEntries.length} enlaces...`);\n      \n        const results = await Promise.all(\n            firstFiveEntries.map(async ([linkId, url]) => {\n                console.log(`Iniciando procesamiento de ${linkId}...`);\n                const text = await getCleanedText(url);\n                console.log(`Finalizado procesamiento de ${linkId}`);\n                return {\n                    linkId,\n                    url,\n                    text\n                };\n            })\n        );\n\n        console.log('Formateando resultados...');\n        const formattedResults = results\n            .map(result =>\n                `${result.linkId}:\\n` +\n                `URL: ${result.url}\\n` +\n                `CONTENIDO:\\n${result.text}\\n` +\n                `----------------------------------------\\n`\n            )\n            .join('\\n');\n\n        return formattedResults;\n    } catch (error) {\n        console.error(\"Error detallado procesando los enlaces:\", error);\n        return `Error procesando los enlaces: ${error.message}`;\n    }\n}\n\nconst links = $link;\nif (!links) {\n    console.error(\"Variable $link está vacía\");\n    return \"Error: No se proporcionaron enlaces. La variable $link está vacía.\";\n}\n\nconsole.log('Iniciando proceso completo...');\nreturn await processFirstFiveLinks(links);"
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "customFunction_1-output-output-string|number|boolean|json|array",
                "name": "output",
                "label": "Output",
                "description": "",
                "type": "string | number | boolean | json | array"
              },
              {
                "id": "customFunction_1-output-EndingNode-CustomFunction",
                "name": "EndingNode",
                "label": "Ending Node",
                "description": "",
                "type": "CustomFunction"
              }
            ],
            "default": "output"
          }
        ],
        "outputs": {
          "output": "output"
        },
        "selected": false
      },
      "width": 300,
      "height": 726,
      "selected": false,
      "positionAbsolute": {
        "x": 1916.477105496279,
        "y": 223.6826688678588
      },
      "dragging": false
    },
    {
      "id": "stickyNote_0",
      "position": {
        "x": 677.9534605978348,
        "y": 988.0375866989754
      },
      "type": "stickyNote",
      "data": {
        "id": "stickyNote_0",
        "label": "Sticky Note",
        "version": 2,
        "name": "stickyNote",
        "type": "StickyNote",
        "baseClasses": [
          "StickyNote"
        ],
        "tags": [
          "Utilities"
        ],
        "category": "Utilities",
        "description": "Add a sticky note",
        "inputParams": [
          {
            "label": "",
            "name": "note",
            "type": "string",
            "rows": 1,
            "placeholder": "Type something here",
            "optional": true,
            "id": "stickyNote_0-input-note-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "note": "Esta función busca el query inicial para obtener los links que necesitaremos scrapear para obtener la información que necesitamos."
        },
        "outputAnchors": [
          {
            "id": "stickyNote_0-output-stickyNote-StickyNote",
            "name": "stickyNote",
            "label": "StickyNote",
            "description": "Add a sticky note",
            "type": "StickyNote"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 103,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 677.9534605978348,
        "y": 988.0375866989754
      }
    },
    {
      "id": "promptTemplate_1",
      "position": {
        "x": 2371.8896147407945,
        "y": 584.8025289529037
      },
      "type": "customNode",
      "data": {
        "id": "promptTemplate_1",
        "label": "Prompt Template",
        "version": 1,
        "name": "promptTemplate",
        "type": "PromptTemplate",
        "baseClasses": [
          "PromptTemplate",
          "BaseStringPromptTemplate",
          "BasePromptTemplate",
          "Runnable"
        ],
        "category": "Prompts",
        "description": "Schema to represent a basic prompt for an LLM",
        "inputParams": [
          {
            "label": "Template",
            "name": "template",
            "type": "string",
            "rows": 4,
            "placeholder": "What is a good name for a company that makes {product}?",
            "id": "promptTemplate_1-input-template-string"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "promptTemplate_1-input-promptValues-json"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "template": "Eres un comunicador experto. Te voy a pasar mucha información, que debes digerir y presentar de una manera que pueda ser entendida en su completitud por cualquier usuario.\n\nLa información va a incluir 5 webs con información. Tu objetivo es transmitir la verdad y toda la información que sea posible (haciendo referencia si citas algo a la web de donde has obtenido dicha información).\n\nDebes de dar esta explicación en español.\n\nTe dejo a continuación toda la información que debes de procesar:\n{info}",
          "promptValues": "{\"info\":\"{{customFunction_0.data.instance}}\"}"
        },
        "outputAnchors": [
          {
            "id": "promptTemplate_1-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable",
            "name": "promptTemplate",
            "label": "PromptTemplate",
            "description": "Schema to represent a basic prompt for an LLM",
            "type": "PromptTemplate | BaseStringPromptTemplate | BasePromptTemplate | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 513,
      "selected": false,
      "positionAbsolute": {
        "x": 2371.8896147407945,
        "y": 584.8025289529037
      },
      "dragging": false
    },
    {
      "id": "stickyNote_1",
      "position": {
        "x": 1926.2210713774173,
        "y": 994.991607202307
      },
      "type": "stickyNote",
      "data": {
        "id": "stickyNote_1",
        "label": "Sticky Note",
        "version": 2,
        "name": "stickyNote",
        "type": "StickyNote",
        "baseClasses": [
          "StickyNote"
        ],
        "tags": [
          "Utilities"
        ],
        "category": "Utilities",
        "description": "Add a sticky note",
        "inputParams": [
          {
            "label": "",
            "name": "note",
            "type": "string",
            "rows": 1,
            "placeholder": "Type something here",
            "optional": true,
            "id": "stickyNote_1-input-note-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "note": "Esta función obtiene el raw text de los 5 primeros links del json que da como output la Chain llamada \"procesador_de_links\""
        },
        "outputAnchors": [
          {
            "id": "stickyNote_1-output-stickyNote-StickyNote",
            "name": "stickyNote",
            "label": "StickyNote",
            "description": "Add a sticky note",
            "type": "StickyNote"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 82,
      "selected": false,
      "positionAbsolute": {
        "x": 1926.2210713774173,
        "y": 994.991607202307
      },
      "dragging": false
    },
    {
      "id": "stickyNote_2",
      "position": {
        "x": 2798.6100468232735,
        "y": 1020.7283754133864
      },
      "type": "stickyNote",
      "data": {
        "id": "stickyNote_2",
        "label": "Sticky Note",
        "version": 2,
        "name": "stickyNote",
        "type": "StickyNote",
        "baseClasses": [
          "StickyNote"
        ],
        "tags": [
          "Utilities"
        ],
        "category": "Utilities",
        "description": "Add a sticky note",
        "inputParams": [
          {
            "label": "",
            "name": "note",
            "type": "string",
            "rows": 1,
            "placeholder": "Type something here",
            "optional": true,
            "id": "stickyNote_2-input-note-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "note": "Razona y procesa la información que hemos obtenido a través de los 5 primeros links de la lista de enlaces inicial."
        },
        "outputAnchors": [
          {
            "id": "stickyNote_2-output-stickyNote-StickyNote",
            "name": "stickyNote",
            "label": "StickyNote",
            "description": "Add a sticky note",
            "type": "StickyNote"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 82,
      "selected": false,
      "positionAbsolute": {
        "x": 2798.6100468232735,
        "y": 1020.7283754133864
      },
      "dragging": false
    },
    {
      "id": "llmChain_1",
      "position": {
        "x": 2788.960438732253,
        "y": 479.64328531117434
      },
      "type": "customNode",
      "data": {
        "id": "llmChain_1",
        "label": "LLM Chain",
        "version": 3,
        "name": "llmChain",
        "type": "LLMChain",
        "baseClasses": [
          "LLMChain",
          "BaseChain",
          "Runnable"
        ],
        "category": "Chains",
        "description": "Chain to run queries against LLMs",
        "inputParams": [
          {
            "label": "Chain Name",
            "name": "chainName",
            "type": "string",
            "placeholder": "Name Your Chain",
            "optional": true,
            "id": "llmChain_1-input-chainName-string"
          }
        ],
        "inputAnchors": [
          {
            "label": "Language Model",
            "name": "model",
            "type": "BaseLanguageModel",
            "id": "llmChain_1-input-model-BaseLanguageModel"
          },
          {
            "label": "Prompt",
            "name": "prompt",
            "type": "BasePromptTemplate",
            "id": "llmChain_1-input-prompt-BasePromptTemplate"
          },
          {
            "label": "Output Parser",
            "name": "outputParser",
            "type": "BaseLLMOutputParser",
            "optional": true,
            "id": "llmChain_1-input-outputParser-BaseLLMOutputParser"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "llmChain_1-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "model": "{{groqChat_0.data.instance}}",
          "prompt": "{{promptTemplate_1.data.instance}}",
          "outputParser": "",
          "inputModeration": "",
          "chainName": "comunicador"
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "llmChain_1-output-llmChain-LLMChain|BaseChain|Runnable",
                "name": "llmChain",
                "label": "LLM Chain",
                "description": "",
                "type": "LLMChain | BaseChain | Runnable"
              },
              {
                "id": "llmChain_1-output-outputPrediction-string|json",
                "name": "outputPrediction",
                "label": "Output Prediction",
                "description": "",
                "type": "string | json"
              }
            ],
            "default": "llmChain"
          }
        ],
        "outputs": {
          "output": "outputPrediction"
        },
        "selected": false
      },
      "width": 300,
      "height": 508,
      "selected": false,
      "positionAbsolute": {
        "x": 2788.960438732253,
        "y": 479.64328531117434
      },
      "dragging": false
    },
    {
      "id": "groqChat_0",
      "position": {
        "x": 2371.5938956186574,
        "y": -56.32741933470186
      },
      "type": "customNode",
      "data": {
        "id": "groqChat_0",
        "label": "GroqChat",
        "version": 4,
        "name": "groqChat",
        "type": "GroqChat",
        "baseClasses": [
          "GroqChat",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around Groq API with LPU Inference Engine",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "groqApi"
            ],
            "optional": true,
            "id": "groqChat_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "placeholder": "llama3-70b-8192",
            "id": "groqChat_0-input-modelName-asyncOptions"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "groqChat_0-input-temperature-number"
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "id": "groqChat_0-input-streaming-boolean"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "groqChat_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "deepseek-r1-distill-llama-70b",
          "temperature": "0.2",
          "streaming": true
        },
        "outputAnchors": [
          {
            "id": "groqChat_0-output-groqChat-GroqChat|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "groqChat",
            "label": "GroqChat",
            "description": "Wrapper around Groq API with LPU Inference Engine",
            "type": "GroqChat | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 618,
      "selected": false,
      "positionAbsolute": {
        "x": 2371.5938956186574,
        "y": -56.32741933470186
      },
      "dragging": false
    },
    {
      "id": "llmChain_2",
      "position": {
        "x": 3659.1703167611795,
        "y": 483.3025061518665
      },
      "type": "customNode",
      "data": {
        "id": "llmChain_2",
        "label": "LLM Chain",
        "version": 3,
        "name": "llmChain",
        "type": "LLMChain",
        "baseClasses": [
          "LLMChain",
          "BaseChain",
          "Runnable"
        ],
        "category": "Chains",
        "description": "Chain to run queries against LLMs",
        "inputParams": [
          {
            "label": "Chain Name",
            "name": "chainName",
            "type": "string",
            "placeholder": "Name Your Chain",
            "optional": true,
            "id": "llmChain_2-input-chainName-string"
          }
        ],
        "inputAnchors": [
          {
            "label": "Language Model",
            "name": "model",
            "type": "BaseLanguageModel",
            "id": "llmChain_2-input-model-BaseLanguageModel"
          },
          {
            "label": "Prompt",
            "name": "prompt",
            "type": "BasePromptTemplate",
            "id": "llmChain_2-input-prompt-BasePromptTemplate"
          },
          {
            "label": "Output Parser",
            "name": "outputParser",
            "type": "BaseLLMOutputParser",
            "optional": true,
            "id": "llmChain_2-input-outputParser-BaseLLMOutputParser"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "llmChain_2-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "model": "{{groqChat_1.data.instance}}",
          "prompt": "{{promptTemplate_2.data.instance}}",
          "outputParser": "",
          "inputModeration": "",
          "chainName": "formateo_del_mensaje"
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "llmChain_2-output-llmChain-LLMChain|BaseChain|Runnable",
                "name": "llmChain",
                "label": "LLM Chain",
                "description": "",
                "type": "LLMChain | BaseChain | Runnable"
              },
              {
                "id": "llmChain_2-output-outputPrediction-string|json",
                "name": "outputPrediction",
                "label": "Output Prediction",
                "description": "",
                "type": "string | json"
              }
            ],
            "default": "llmChain"
          }
        ],
        "outputs": {
          "output": "llmChain"
        },
        "selected": false
      },
      "width": 300,
      "height": 508,
      "selected": false,
      "positionAbsolute": {
        "x": 3659.1703167611795,
        "y": 483.3025061518665
      },
      "dragging": false
    },
    {
      "id": "groqChat_1",
      "position": {
        "x": 3208.870786081355,
        "y": -118.53417362646641
      },
      "type": "customNode",
      "data": {
        "id": "groqChat_1",
        "label": "GroqChat",
        "version": 4,
        "name": "groqChat",
        "type": "GroqChat",
        "baseClasses": [
          "GroqChat",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around Groq API with LPU Inference Engine",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "groqApi"
            ],
            "optional": true,
            "id": "groqChat_1-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "placeholder": "llama3-70b-8192",
            "id": "groqChat_1-input-modelName-asyncOptions"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "groqChat_1-input-temperature-number"
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "id": "groqChat_1-input-streaming-boolean"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "groqChat_1-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "llama-3.3-70b-versatile",
          "temperature": "0.1",
          "streaming": true
        },
        "outputAnchors": [
          {
            "id": "groqChat_1-output-groqChat-GroqChat|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "groqChat",
            "label": "GroqChat",
            "description": "Wrapper around Groq API with LPU Inference Engine",
            "type": "GroqChat | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 618,
      "selected": false,
      "positionAbsolute": {
        "x": 3208.870786081355,
        "y": -118.53417362646641
      },
      "dragging": false
    },
    {
      "id": "promptTemplate_2",
      "position": {
        "x": 3216.4849468848765,
        "y": 570.1656455901356
      },
      "type": "customNode",
      "data": {
        "id": "promptTemplate_2",
        "label": "Prompt Template",
        "version": 1,
        "name": "promptTemplate",
        "type": "PromptTemplate",
        "baseClasses": [
          "PromptTemplate",
          "BaseStringPromptTemplate",
          "BasePromptTemplate",
          "Runnable"
        ],
        "category": "Prompts",
        "description": "Schema to represent a basic prompt for an LLM",
        "inputParams": [
          {
            "label": "Template",
            "name": "template",
            "type": "string",
            "rows": 4,
            "placeholder": "What is a good name for a company that makes {product}?",
            "id": "promptTemplate_2-input-template-string"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "promptTemplate_2-input-promptValues-json"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "template": "Eres un presentador de información experto. \nTe voy a pasar un texto y debes de devolver exactamente lo mismo a lo que te de, pero quitando todo lo que venga dentro de las etiquetas <think> </think> incluidas las propias etiquetas. \nDebes de incluir al final de lo que escribas los links que también te voy a pasar.\n\nEl texto:\n{texto}\n\nLos links:\n{link}",
          "promptValues": "{\"texto\":\"{{llmChain_1.data.instance}}\",\"link\":\"{{getVariable_0.data.instance}}\"}"
        },
        "outputAnchors": [
          {
            "id": "promptTemplate_2-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable",
            "name": "promptTemplate",
            "label": "PromptTemplate",
            "description": "Schema to represent a basic prompt for an LLM",
            "type": "PromptTemplate | BaseStringPromptTemplate | BasePromptTemplate | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 513,
      "selected": false,
      "positionAbsolute": {
        "x": 3216.4849468848765,
        "y": 570.1656455901356
      },
      "dragging": false
    },
    {
      "id": "setVariable_0",
      "position": {
        "x": 1496.9796598967898,
        "y": -3.6009039429977747
      },
      "type": "customNode",
      "data": {
        "id": "setVariable_0",
        "label": "Set Variable",
        "version": 2.1,
        "name": "setVariable",
        "type": "SetVariable",
        "baseClasses": [
          "SetVariable",
          "Utilities"
        ],
        "tags": [
          "Utilities"
        ],
        "category": "Utilities",
        "description": "Set variable which can be retrieved at a later stage. Variable is only available during runtime.",
        "inputParams": [
          {
            "label": "Variable Name",
            "name": "variableName",
            "type": "string",
            "placeholder": "var1",
            "id": "setVariable_0-input-variableName-string"
          },
          {
            "label": "Show Output",
            "name": "showOutput",
            "description": "Show the output result in the Prediction API response",
            "type": "boolean",
            "optional": true,
            "additionalParams": true,
            "id": "setVariable_0-input-showOutput-boolean"
          }
        ],
        "inputAnchors": [
          {
            "label": "Input",
            "name": "input",
            "type": "string | number | boolean | json | array",
            "optional": true,
            "list": true,
            "id": "setVariable_0-input-input-string | number | boolean | json | array"
          }
        ],
        "inputs": {
          "input": [
            "{{llmChain_0.data.instance}}"
          ],
          "variableName": "links",
          "showOutput": ""
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "setVariable_0-output-output-string|number|boolean|json|array",
                "name": "output",
                "label": "Output",
                "description": "",
                "type": "string | number | boolean | json | array"
              }
            ],
            "default": "output"
          }
        ],
        "outputs": {
          "output": "output"
        },
        "selected": false
      },
      "width": 300,
      "height": 408,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 1496.9796598967898,
        "y": -3.6009039429977747
      }
    },
    {
      "id": "getVariable_0",
      "position": {
        "x": 2790.6558387378427,
        "y": 1141.2915643994031
      },
      "type": "customNode",
      "data": {
        "id": "getVariable_0",
        "label": "Get Variable",
        "version": 2,
        "name": "getVariable",
        "type": "GetVariable",
        "baseClasses": [
          "GetVariable",
          "Utilities"
        ],
        "tags": [
          "Utilities"
        ],
        "category": "Utilities",
        "description": "Get variable that was saved using Set Variable node",
        "inputParams": [
          {
            "label": "Variable Name",
            "name": "variableName",
            "type": "string",
            "placeholder": "var1",
            "id": "getVariable_0-input-variableName-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "variableName": "links"
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "getVariable_0-output-output-string|number|boolean|json|array",
                "name": "output",
                "label": "Output",
                "description": "",
                "type": "string | number | boolean | json | array"
              }
            ],
            "default": "output"
          }
        ],
        "outputs": {
          "output": "output"
        },
        "selected": false
      },
      "width": 300,
      "height": 305,
      "selected": false,
      "positionAbsolute": {
        "x": 2790.6558387378427,
        "y": 1141.2915643994031
      },
      "dragging": false
    },
    {
      "id": "stickyNote_3",
      "position": {
        "x": 3656.4997773296373,
        "y": 1022.1682802262994
      },
      "type": "stickyNote",
      "data": {
        "id": "stickyNote_3",
        "label": "Sticky Note",
        "version": 2,
        "name": "stickyNote",
        "type": "StickyNote",
        "baseClasses": [
          "StickyNote"
        ],
        "tags": [
          "Utilities"
        ],
        "category": "Utilities",
        "description": "Add a sticky note",
        "inputParams": [
          {
            "label": "",
            "name": "note",
            "type": "string",
            "rows": 1,
            "placeholder": "Type something here",
            "optional": true,
            "id": "stickyNote_3-input-note-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "note": "Arregla el formato del mensaje final e incluye los links usados para la investigación."
        },
        "outputAnchors": [
          {
            "id": "stickyNote_3-output-stickyNote-StickyNote",
            "name": "stickyNote",
            "label": "StickyNote",
            "description": "Add a sticky note",
            "type": "StickyNote"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 82,
      "selected": false,
      "positionAbsolute": {
        "x": 3656.4997773296373,
        "y": 1022.1682802262994
      },
      "dragging": false
    },
    {
      "id": "stickyNote_4",
      "position": {
        "x": 1508.2464868589152,
        "y": 1017.1135934255884
      },
      "type": "stickyNote",
      "data": {
        "id": "stickyNote_4",
        "label": "Sticky Note",
        "version": 2,
        "name": "stickyNote",
        "type": "StickyNote",
        "baseClasses": [
          "StickyNote"
        ],
        "tags": [
          "Utilities"
        ],
        "category": "Utilities",
        "description": "Add a sticky note",
        "inputParams": [
          {
            "label": "",
            "name": "note",
            "type": "string",
            "rows": 1,
            "placeholder": "Type something here",
            "optional": true,
            "id": "stickyNote_4-input-note-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "note": "Esta Chain recibe como input todo el output de BraveSearchAPI y devuelve en formato JSON una lista de los enlaces relevantes al query de la búsqueda inicial."
        },
        "outputAnchors": [
          {
            "id": "stickyNote_4-output-stickyNote-StickyNote",
            "name": "stickyNote",
            "label": "StickyNote",
            "description": "Add a sticky note",
            "type": "StickyNote"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 103,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 1508.2464868589152,
        "y": 1017.1135934255884
      }
    }
  ],
  "edges": [
    {
      "source": "braveSearchAPI_0",
      "sourceHandle": "braveSearchAPI_0-output-braveSearchAPI-BraveSearchAPI|Tool|StructuredTool|Runnable",
      "target": "customFunction_0",
      "targetHandle": "customFunction_0-input-tools-Tool",
      "type": "buttonedge",
      "id": "braveSearchAPI_0-braveSearchAPI_0-output-braveSearchAPI-BraveSearchAPI|Tool|StructuredTool|Runnable-customFunction_0-customFunction_0-input-tools-Tool"
    },
    {
      "source": "customFunction_0",
      "sourceHandle": "customFunction_0-output-output-string|number|boolean|json|array",
      "target": "promptTemplate_0",
      "targetHandle": "promptTemplate_0-input-promptValues-json",
      "type": "buttonedge",
      "id": "customFunction_0-customFunction_0-output-output-string|number|boolean|json|array-promptTemplate_0-promptTemplate_0-input-promptValues-json"
    },
    {
      "source": "promptTemplate_0",
      "sourceHandle": "promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable",
      "target": "llmChain_0",
      "targetHandle": "llmChain_0-input-prompt-BasePromptTemplate",
      "type": "buttonedge",
      "id": "promptTemplate_0-promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable-llmChain_0-llmChain_0-input-prompt-BasePromptTemplate"
    },
    {
      "source": "chatGoogleGenerativeAI_0",
      "sourceHandle": "chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "llmChain_0",
      "targetHandle": "llmChain_0-input-model-BaseLanguageModel",
      "type": "buttonedge",
      "id": "chatGoogleGenerativeAI_0-chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable-llmChain_0-llmChain_0-input-model-BaseLanguageModel"
    },
    {
      "source": "llmChain_0",
      "sourceHandle": "llmChain_0-output-outputPrediction-string|json",
      "target": "customFunction_1",
      "targetHandle": "customFunction_1-input-functionInputVariables-json",
      "type": "buttonedge",
      "id": "llmChain_0-llmChain_0-output-outputPrediction-string|json-customFunction_1-customFunction_1-input-functionInputVariables-json"
    },
    {
      "source": "groqChat_0",
      "sourceHandle": "groqChat_0-output-groqChat-GroqChat|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "llmChain_1",
      "targetHandle": "llmChain_1-input-model-BaseLanguageModel",
      "type": "buttonedge",
      "id": "groqChat_0-groqChat_0-output-groqChat-GroqChat|BaseChatModel|BaseLanguageModel|Runnable-llmChain_1-llmChain_1-input-model-BaseLanguageModel"
    },
    {
      "source": "promptTemplate_1",
      "sourceHandle": "promptTemplate_1-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable",
      "target": "llmChain_1",
      "targetHandle": "llmChain_1-input-prompt-BasePromptTemplate",
      "type": "buttonedge",
      "id": "promptTemplate_1-promptTemplate_1-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable-llmChain_1-llmChain_1-input-prompt-BasePromptTemplate"
    },
    {
      "source": "customFunction_1",
      "sourceHandle": "customFunction_1-output-output-string|number|boolean|json|array",
      "target": "promptTemplate_1",
      "targetHandle": "promptTemplate_1-input-promptValues-json",
      "type": "buttonedge",
      "id": "customFunction_1-customFunction_1-output-output-string|number|boolean|json|array-promptTemplate_1-promptTemplate_1-input-promptValues-json"
    },
    {
      "source": "llmChain_1",
      "sourceHandle": "llmChain_1-output-outputPrediction-string|json",
      "target": "promptTemplate_2",
      "targetHandle": "promptTemplate_2-input-promptValues-json",
      "type": "buttonedge",
      "id": "llmChain_1-llmChain_1-output-outputPrediction-string|json-promptTemplate_2-promptTemplate_2-input-promptValues-json"
    },
    {
      "source": "groqChat_1",
      "sourceHandle": "groqChat_1-output-groqChat-GroqChat|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "llmChain_2",
      "targetHandle": "llmChain_2-input-model-BaseLanguageModel",
      "type": "buttonedge",
      "id": "groqChat_1-groqChat_1-output-groqChat-GroqChat|BaseChatModel|BaseLanguageModel|Runnable-llmChain_2-llmChain_2-input-model-BaseLanguageModel"
    },
    {
      "source": "promptTemplate_2",
      "sourceHandle": "promptTemplate_2-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable",
      "target": "llmChain_2",
      "targetHandle": "llmChain_2-input-prompt-BasePromptTemplate",
      "type": "buttonedge",
      "id": "promptTemplate_2-promptTemplate_2-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable-llmChain_2-llmChain_2-input-prompt-BasePromptTemplate"
    },
    {
      "source": "llmChain_0",
      "sourceHandle": "llmChain_0-output-outputPrediction-string|json",
      "target": "setVariable_0",
      "targetHandle": "setVariable_0-input-input-string | number | boolean | json | array",
      "type": "buttonedge",
      "id": "llmChain_0-llmChain_0-output-outputPrediction-string|json-setVariable_0-setVariable_0-input-input-string | number | boolean | json | array"
    },
    {
      "source": "getVariable_0",
      "sourceHandle": "getVariable_0-output-output-string|number|boolean|json|array",
      "target": "promptTemplate_2",
      "targetHandle": "promptTemplate_2-input-promptValues-json",
      "type": "buttonedge",
      "id": "getVariable_0-getVariable_0-output-output-string|number|boolean|json|array-promptTemplate_2-promptTemplate_2-input-promptValues-json"
    }
  ]
}